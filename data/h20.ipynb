{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>6 mins 00 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Oslo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.42.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 10 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_sigurdskatvedt_bck8fk</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>11.03 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.4 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------------\n",
       "H2O_cluster_uptime:         6 mins 00 secs\n",
       "H2O_cluster_timezone:       Europe/Oslo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.42.0.3\n",
       "H2O_cluster_version_age:    1 month and 10 days\n",
       "H2O_cluster_name:           H2O_from_python_sigurdskatvedt_bck8fk\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    11.03 Gb\n",
       "H2O_cluster_total_cores:    10\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.4 final\n",
       "--------------------------  -------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zb/xfl28cf152d70jcqdxf40t540000gn/T/ipykernel_74374/252412350.py:58: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "13:55:49.341: AutoML: XGBoost is not available; skipping it.\n",
      "13:55:49.343: _train param, Dropping bad and constant columns: [snow_drift:idx, elevation:m]\n",
      "\n",
      "█████████████\n",
      "13:56:45.318: XRT_1_AutoML_3_20231003_135549 [DRF XRT (Extremely Randomized Trees)] failed: java.lang.AssertionError\n",
      "\n",
      "██\n",
      "13:56:50.294: _train param, Dropping bad and constant columns: [snow_drift:idx, elevation:m]\n",
      "\n",
      "████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Dataset a - Mean Absolute Error on validation set: 168.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zb/xfl28cf152d70jcqdxf40t540000gn/T/ipykernel_74374/252412350.py:58: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "14:00:53.76: AutoML: XGBoost is not available; skipping it.\n",
      "14:00:53.78: _train param, Dropping bad and constant columns: [elevation:m]\n",
      "\n",
      "████████████\n",
      "14:01:46.544: XRT_1_AutoML_4_20231003_140053 [DRF XRT (Extremely Randomized Trees)] failed: java.lang.AssertionError\n",
      "\n",
      "████\n",
      "14:01:55.954: _train param, Dropping bad and constant columns: [elevation:m]\n",
      "\n",
      "███████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Dataset b - Mean Absolute Error on validation set: 25.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zb/xfl28cf152d70jcqdxf40t540000gn/T/ipykernel_74374/252412350.py:58: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "14:05:56.393: AutoML: XGBoost is not available; skipping it.\n",
      "14:05:56.394: _train param, Dropping bad and constant columns: [elevation:m]\n",
      "\n",
      "████████████\n",
      "14:06:37.973: XRT_1_AutoML_5_20231003_140556 [DRF XRT (Extremely Randomized Trees)] failed: java.lang.AssertionError\n",
      "\n",
      "██\n",
      "14:06:42.232: _train param, Dropping bad and constant columns: [elevation:m]\n",
      "\n",
      "█████████████████████████████████████████████████| (done) 100%\n",
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Dataset c - Mean Absolute Error on validation set: 15.92\n",
      "H2O session _sid_9e13 closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import xgboost\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "h2o.init(max_mem_size='12G')\n",
    "\n",
    "# Data loading\n",
    "data_files = {\n",
    "    'a': {\n",
    "        'train': 'A/train_targets.parquet',\n",
    "        'estimated': 'A/X_train_estimated.parquet',\n",
    "        'observed': 'A/X_train_observed.parquet'\n",
    "    },\n",
    "    'b': {\n",
    "        'train': 'B/train_targets.parquet',\n",
    "        'estimated': 'B/X_train_estimated.parquet',\n",
    "        'observed': 'B/X_train_observed.parquet'\n",
    "    },\n",
    "    'c': {\n",
    "        'train': 'C/train_targets.parquet',\n",
    "        'estimated': 'C/X_train_estimated.parquet',\n",
    "        'observed': 'C/X_train_observed.parquet'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_data(targets, observed, estimated, test):\n",
    "    \"\"\"\n",
    "    Preprocess the data by resampling, merging with targets, and dropping unnecessary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - targets: Target dataframe with 'time' and target values.\n",
    "    - observed: Dataframe with observed features.\n",
    "    - estimated: Dataframe with estimated features.\n",
    "    - test: Dataframe with test features.\n",
    "    \n",
    "    Returns:\n",
    "    - Preprocessed dataframes ready for training and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the datetime columns are in datetime format\n",
    "    targets['time'] = pd.to_datetime(targets['time'])\n",
    "    observed['date_forecast'] = pd.to_datetime(observed['date_forecast'])\n",
    "    estimated['date_forecast'] = pd.to_datetime(estimated['date_forecast'])\n",
    "    test['date_forecast'] = pd.to_datetime(test['date_forecast'])\n",
    "\n",
    "    # Ensure data is sorted by date_forecast\n",
    "    targets = targets.sort_values(by='time')\n",
    "    observed = observed.sort_values(by='date_forecast')\n",
    "    estimated = estimated.sort_values(by='date_forecast')\n",
    "    test = test.sort_values(by='date_forecast')\n",
    "\n",
    "    # Identify boolean columns\n",
    "    boolean_features = [col for col in observed.columns if observed[col].dropna().isin([0.0, 1.0]).all()]\n",
    "\n",
    "    # Forward fill NaNs for boolean columns\n",
    "    for df in [observed, estimated, test]:\n",
    "        df[boolean_features] = df[boolean_features].fillna(method='ffill')\n",
    "\n",
    "    # Forward fill for time-series data (for non-boolean columns)\n",
    "    for df in [observed, estimated, test]:\n",
    "        df[df.columns.difference(boolean_features)] = df[df.columns.difference(boolean_features)].fillna(method='ffill')\n",
    "\n",
    "    \"\"\"  \n",
    "    # Forward fill for time-series data\n",
    "    observed.fillna(method='ffill', inplace=True)\n",
    "    estimated.fillna(method='ffill', inplace=True)\n",
    "    test.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Fill NaNs in boolean features with 0\n",
    "    boolean_features = [col for col in observed.columns if observed[col].dropna().isin([0.0, 1.0]).all()]\n",
    "    observed[boolean_features] = observed[boolean_features].fillna(method='ffill')\n",
    "    estimated[boolean_features] = estimated[boolean_features].fillna(method='ffill')\n",
    "    test[boolean_features] = test[boolean_features].fillna(method='ffill') \n",
    "    \"\"\"\n",
    "\n",
    "    # Resample observed, estimated, and test data to 1 hour using mean() as aggregator\n",
    "    # and drop rows where all columns are NaN\n",
    "    observed_resampled = observed.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    estimated_resampled = estimated.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "    test_resampled = test.set_index('date_forecast').resample('1H').mean().dropna(how='all').reset_index()\n",
    "\n",
    "    # Round boolean columns after resampling\n",
    "    for df in [observed_resampled, estimated_resampled, test_resampled]:\n",
    "        df[boolean_features] = df[boolean_features].round(0)\n",
    "\n",
    "    observed_resampled['estimated'] = 0\n",
    "    estimated_resampled['estimated'] = 1\n",
    "    test_resampled['estimated'] = 1\n",
    "    \n",
    "    # Merge the observed and estimated data\n",
    "    weather_data = pd.concat([observed_resampled, estimated_resampled])\n",
    "\n",
    "    # Merge with target values\n",
    "    merged_data = pd.merge(targets, weather_data, how='inner', left_on='time', right_on='date_forecast')\n",
    "\n",
    "    # Time-Based Features (training data)\n",
    "    merged_data['hour'] = merged_data['date_forecast'].dt.hour\n",
    "    merged_data['sin_hour'] = np.sin(2 * np.pi * merged_data['hour'] / 24)\n",
    "    merged_data['cos_hour'] = np.cos(2 * np.pi * merged_data['hour'] / 24)\n",
    "    # merged_data['day_of_week'] = merged_data['date_forecast'].dt.dayofweek\n",
    "    merged_data['month'] = merged_data['date_forecast'].dt.month\n",
    "    merged_data['sin_month'] = np.sin(2 * np.pi * merged_data['month'] / 12)\n",
    "    merged_data['cos_month'] = np.cos(2 * np.pi * merged_data['month'] / 12)\n",
    "\n",
    "    # Time-Based Features (test data)\n",
    "    test_resampled['hour'] = test_resampled['date_forecast'].dt.hour\n",
    "    test_resampled['sin_hour'] = np.sin(2 * np.pi * test_resampled['hour'] / 24)\n",
    "    test_resampled['cos_hour'] = np.cos(2 * np.pi * test_resampled['hour'] / 24)\n",
    "    # test_resampled['day_of_week'] = test_resampled['date_forecast'].dt.dayofweek\n",
    "    test_resampled['month'] = test_resampled['date_forecast'].dt.month\n",
    "    test_resampled['sin_month'] = np.sin(2 * np.pi * test_resampled['month'] / 12)\n",
    "    test_resampled['cos_month'] = np.cos(2 * np.pi * test_resampled['month'] / 12)\n",
    "\n",
    "\n",
    "    # Drop non-feature columns\n",
    "    merged_data = merged_data.drop(columns=['time', 'date_forecast', 'pv_measurement', 'snow_density:kgm3'])\n",
    "    test_resampled = test_resampled.drop(columns=['date_forecast', 'snow_density:kgm3'])\n",
    "\n",
    "    # fixing ceiling_height NaN value\n",
    "    merged_data['ceiling_height_agl:m'].fillna(0, inplace=True)\n",
    "    test_resampled['ceiling_height_agl:m'].fillna(0, inplace=True)\n",
    "  \n",
    "    \n",
    "    return merged_data, test_resampled\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "for dataset_name, file_paths in data_files.items():\n",
    "    train_data = pd.read_parquet(file_paths['train'])\n",
    "    estimated_data = pd.read_parquet(file_paths['estimated'])\n",
    "    observed_data = pd.read_parquet(file_paths['observed'])\n",
    "\n",
    "    X_train, _ = preprocess_data(train_data, observed_data, estimated_data)\n",
    "\n",
    "    # Convert pandas dataframe to H2OFrame\n",
    "    X_train_h2o = h2o.H2OFrame(X_train)\n",
    "\n",
    "    # Specify target and predictor columns\n",
    "    y = \"pv_measurement\"\n",
    "    X = [col for col in X_train_h2o.columns if col != y]\n",
    "\n",
    "    # Split data into training and validation sets (80% train, 20% validation)\n",
    "    train, val = X_train_h2o.split_frame(ratios=[.8], seed=42)\n",
    "\n",
    "    # Run H2O AutoML\n",
    "    aml = H2OAutoML(max_runtime_secs=300, max_models=20, seed=42, stopping_metric='MAE', sort_metric='MAE')\n",
    "    aml.train(x=X, y=y, training_frame=train)\n",
    "\n",
    "    # Validate the model\n",
    "    preds = aml.leader.predict(val)\n",
    "    performance = aml.leader.model_performance(val)\n",
    "    mae = performance.mae()\n",
    "\n",
    "    print(f\"Dataset {dataset_name} - Mean Absolute Error on validation set: {mae:.2f}\")\n",
    "\n",
    "# Shutdown H2O cluster when finished\n",
    "h2o.cluster().shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
